---
layout: essay
type: essay
title: Lesser of Two Evils
date: 2017-05-02
labels:
  - ethics
  -software engineering
---

<img class="ui medium left floated image" src="../ethics.jpg">

## Ethics in Software Engineering

Software engineering as a discipline gives someone the ability and power to create programs that will run in various ways based on certain conditions. This can be great since software can help automate numerous amounts of tasks that would otherwise take people large amounts of time to complete on their own. This being said, there can be certain ethical implications that come up with regards to designing software when the programs in question are being used in a situation for which it is possible for the output of these programs to have life altering ramifications. Therein lies the ethical dilemma when it comes to software engineering. Overall I believe ethics within the context of software engineering means creating software that will in the worst-case scenario do the lesser of two evils. 

## Ethical Delimma

A great example of an ethical dilemma in software engineering is the programming of self-driving cars. Self-driving cars can be extremely useful for a lot of different reasons; maybe you’re not a good driver so you feel it would be safer to have a car with a self-driving feature, or maybe you don’t want to risk driving home tired or buzzed from drinking that night. These are all reasons that make self-driving cars seem extremely attractive on the surface. However, the ethical dilemma behind this form of software comes in when you must decide what your software will do when you enter a situation for which there is no way to avoid someone getting hurt; whether it be people in your surroundings or the driver and passenger themselves. There are a few different trains of thought to consider when thinking about what the lesser of two evils would be in this case. 

On one hand do you have the car prioritize saving the driver and passenger and risk hurting the pedestrians? Or do you prioritize the pedestrian’s safety over the occupants of the vehicle? It’s hard to really say because each situation is different. For instance, what if there were more pedestrians that would get hurt versus vehicle occupants, do you merely choose to hurt less people? In some respects, this would seem like the easier answer: “go with the option that hurts the least amount of people”. Consider this though: what if one of those passengers is a child? Can we weigh one child over 10 people that aren't children? It is a rough choice because those adults could be parents too and have children that will be left as orphans. There is no correct answer to it. When you start to give yourself a more detailed scenario it makes it even harder to come up with a clear-cut “right” choice, and that is part of what makes ethical decisions so difficult at times.

## Personal Standpoint

From a personal standpoint with regards to self-driving cars and the possible ramifications of the decisions the software behind it can create, I think if forced to choose, I would ultimately have to say programming the car to harm the least amount of people is what I would do. This decision comes from the standpoint of choosing the lesser of two evils, in this case prioritizing saving the most amount of lives possible. It is still very difficult to say what is right and what is wrong since you can never truly weigh one person’s life against another. I think that this is the crux of what makes ethical decisions so hard, and that is the fact that there is never truly a straightforward right answer, when it comes to making these choices everything is relative. 





